---
layout: page
title: About
permalink: /
hide_description: true
---

<div style="display: flex; align-items: center; margin-bottom: 30px; gap: 30px;">
  <img src="/study/assets/img/profile.png" alt="SangYeop Jeong" width="200" style="border-radius: 50%; box-shadow: 0 4px 6px rgba(0,0,0,0.1);">
  <div>
    <h2 style="margin: 0;">SangYeop Jeong (정상엽)</h2>
    <p style="margin: 10px 0; font-size: 1.1em; color: #666;">
      <strong>Undergraduate Research Assistant → Incoming Graduate Student</strong><br>
      Artificial Intelligence, Seoul National University of Science and Technology
    </p>
  </div>
</div>

---

### <u>Research Interests</u>

My research focuses on the intersection of **Computer Vision**, **Computer Graphics**, **Virtual Reality**, and **AI applications**. I'm particularly interested in:

- 3D & 4D Scene Generation (3D Gaussian Splatting)
- VR/AR with AI application
- Multimodal AI Systems(ex. Vision + Audio)
- Human and Computer Interaction(HCI)

---

### <u>Education</u>

<div style="display: flex; align-items: center; margin-bottom: 20px;">
  <img src="/study/assets/img/seoultech-logo.png" alt="SeoulTech Logo" width="150" style="margin-right: 20px;">
  <div>
    <strong>Seoul National University of Science and Technology (SeoulTech)</strong><br>
    서울과학기술대학교<br>
    <ul style="margin-top: 10px;">
      <li>B.S. in Computer Science (Expected: 2027.02)</li>
      <li>M.S. in Computer Science (Starting: 2027.02)</li>
    </ul>
  </div>
</div>

---
### <u>Our Lab</u>

<div style="display: flex; align-items: center; margin-bottom: 20px;">
  <img src="/study/assets/img/brainailab-logo.png" alt="BrAIn Lab Logo" width="250" style="margin-right: 20px;">
  <div>
    <strong>BrAIn Lab (Brain and Artificial Intelligence Lab)</strong><br>
    Department of Applied Artificial Intelligence, SeoulTech<br>
    <strong>Advisor:</strong> Prof. Seong-Eun Kim<br>
    <strong>Position:</strong> Undergraduate Research Intern (Winter 2024 ~ Present)
  </div>
</div>

The BrAIn Lab focuses on developing cutting-edge AI technologies inspired by brain functions. \
 Our research spans multiple domains at the intersection of neuroscience and artificial intelligence:

- **Brain-Computer Interfaces (BCI)**: EEG-based systems for real-world applications
- **Deep Learning for Signal Processing**: Advanced neural architectures for biomedical signals
- **AI for Healthcare**: Intelligent systems for medical diagnosis and patient monitoring
- **Neuromorphic Computing**: Energy-efficient computing inspired by brain structures

\
**Research Highlights**:

- Spike-driven neural networks for energy-efficient signal processing
- EEG decoding for reliable brain-computer interface systems
- Multi-modal AI systems combining various sensory inputs
- Real-time processing systems for clinical applications

The lab is supported by the National Research Foundation of Korea, SeoulTech, and ETRI, with various scholarship opportunities for graduate students. \
\
**Lab Website**: [BrAIn]www.brainailab.com \
\
**My Research Focus**:\
Currently working on Computer Vision projects, with particular interest in integrating vision-based AI with VR/AR applications and exploring multimodal systems that combine visual and audio processing.

---

### <u>Technical Skills</u>

**Programming Languages**  :
- Python
- C / C++ / C#
- html
- java

\
**Frameworks & Tools**  :
- Unreal Engine
- Unity Engine
- MATLAB

---

### <u>Projects</u>

#### User Experience in VR Emotion Recognition Platform (2025.11.15  ~2025.01.22)
Unity-based VR application integrating Convai AI avatars with real-time emotion analysis using acoustic features on Meta Quest 3.

#### EEG-based Reaction Time Classification using Deep Learning
Classification of reaction time from EEG signals using deep learning models (EEGNet, ATCNet, LSTM) to explore the potential for predicting cognitive enhancement on Random Dot Kinematogram dataset.

---

### <u>Contact</u>

**Email**: yeobi5840@gmail.com  
**GitHub**: [github.com/absolutebedrest](https://github.com/absolutebedrest)

---

*Last updated: December 2025*